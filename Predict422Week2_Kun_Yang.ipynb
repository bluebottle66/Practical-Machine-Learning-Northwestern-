{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict422Week2_Kun Yang.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bluebottle66/Practical-Machine-Learning-Northwestern-/blob/master/Predict422Week2_Kun_Yang.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "FuO9Ltd9D7IO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_q-CRDBmFGLp",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "da2e4bad-41c1-43df-95ce-0c787c28eace"
      },
      "cell_type": "code",
      "source": [
        "#test uploading csv file to google colab\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42cc405a-e85b-4f4a-8748-d0f02a66e331\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-42cc405a-e85b-4f4a-8748-d0f02a66e331\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving bank.csv to bank.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TdCRwRX5EDxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "697af17f-8926-4c6d-d82b-a01961752f55"
      },
      "cell_type": "code",
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"bank.csv\" with length 461481 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WP1prBlbFEpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bank=pd.read_csv('bank.csv', sep = ';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PI59hecuEcTd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b967415f-cb94-4108-9234-4fd98869257d"
      },
      "cell_type": "code",
      "source": [
        "print(bank.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4521, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VSiB_8bAFyus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "14e7b6e6-80a7-4890-b4d2-fe2a42e95fb5"
      },
      "cell_type": "code",
      "source": [
        "bank.dropna()\n",
        "print(bank.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4521, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hKBdsdPdNw26",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# use dictionary objects for mapping to 0/1 binary or category\n",
        "response_to_binary = {'no' : 0, 'yes' : 1}\n",
        "YESresponse = np.array(bank['response'].map(response_to_binary))\n",
        "\n",
        "default_to_binary = {'no' : 0, 'yes' : 1}\n",
        "YESdefault = np.array(bank['default'].map(default_to_binary))\n",
        "\n",
        "housing_to_binary = {'no' : 0, 'yes' : 1}\n",
        "YEShousing = np.array(bank['housing'].map(housing_to_binary))\n",
        "\n",
        "loan_to_binary = {'no' : 0, 'yes' : 1}\n",
        "YESloan = np.array(bank['loan'].map(loan_to_binary))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6TwYBNgmoM5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# specify the two classifiers being evaluated\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "names = [\"Naive_Bayes\", \"Logistic_Regression\"]\n",
        "classifiers = [BernoulliNB(alpha=1.0, binarize=0.5, \n",
        "                           class_prior = [0.5, 0.5], fit_prior=False), \n",
        "               LogisticRegression()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MNC9m6dolhg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#select response variable the three binary explanatory variables\n",
        "model_data = np.array([YESdefault,\\\n",
        "    YEShousing,\\\n",
        "    YESloan,\\\n",
        "    YESresponse]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lu9kcGstvN41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "np.random.shuffle(model_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAY9Y3UbvW3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b0b13d11-4d33-4439-d5bb-f7898307d268"
      },
      "cell_type": "code",
      "source": [
        "print('\\nData dimensions:', model_data.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Data dimensions: (4521, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sVSq2vwhvbFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# specify the k-fold cross-validation design\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# ten-fold cross-validation employed here\n",
        "N_FOLDS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wewLSyizvsck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set up numpy array for storing results\n",
        "cv_results = np.zeros((N_FOLDS, len(names)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZW6GecTvw8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4d58149f-7241-4263-e6dd-5143a81cb6e1"
      },
      "cell_type": "code",
      "source": [
        "print(cv_results.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uUVoJbZTwQ-3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits = N_FOLDS, shuffle=False, random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8NDzWLd4wfDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3350
        },
        "outputId": "f45e588d-b2d0-47d5-82b4-90c56d1d0626"
      },
      "cell_type": "code",
      "source": [
        "index_for_fold = 0  # fold count initialized \n",
        "for train_index, test_index in kf.split(model_data):\n",
        "    print('\\nFold index:', index_for_fold,\n",
        "          '------------------------------------------')\n",
        "#   note that 0:model_data.shape[1]-1 slices for explanatory variables\n",
        "#   and model_data.shape[1]-1 is the index for the response variable    \n",
        "    X_train = model_data[train_index, 0:model_data.shape[1]-1]\n",
        "    X_test = model_data[test_index, 0:model_data.shape[1]-1]\n",
        "    y_train = model_data[train_index, model_data.shape[1]-1]\n",
        "    y_test = model_data[test_index, model_data.shape[1]-1]   \n",
        "    print('\\nShape of input data for this fold:',\n",
        "          '\\nData Set: (Observations, Variables)')\n",
        "    print('X_train:', X_train.shape)\n",
        "    print('X_test:',X_test.shape)\n",
        "    print('y_train:', y_train.shape)\n",
        "    print('y_test:',y_test.shape)\n",
        "\n",
        "    index_for_method = 0  # initialize\n",
        "    for name, clf in zip(names, classifiers):\n",
        "        print('\\nClassifier evaluation for:', name)\n",
        "        print('  Scikit Learn method:', clf)\n",
        "        clf.fit(X_train, y_train)  # fit on the train set for this fold\n",
        "        # evaluate on the test set for this fold\n",
        "        y_test_predict = clf.predict_proba(X_test)\n",
        "        fold_method_result = roc_auc_score(y_test, y_test_predict[:,1]) \n",
        "        print('Area under ROC curve:', fold_method_result)\n",
        "        cv_results[index_for_fold, index_for_method] = fold_method_result\n",
        "        index_for_method += 1\n",
        "  \n",
        "    index_for_fold += 1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold index: 0 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4068, 3)\n",
            "X_test: (453, 3)\n",
            "y_train: (4068,)\n",
            "y_test: (453,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.6103395870453832\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.6103395870453832\n",
            "\n",
            "Fold index: 1 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.5740795071145665\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.5740795071145665\n",
            "\n",
            "Fold index: 2 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.654569142006328\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.654569142006328\n",
            "\n",
            "Fold index: 3 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.5872354281992836\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.5872354281992836\n",
            "\n",
            "Fold index: 4 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.5844565027131104\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.5844565027131104\n",
            "\n",
            "Fold index: 5 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.6539908979520392\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.6629179065289692\n",
            "\n",
            "Fold index: 6 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.625049966688874\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.6288696424605817\n",
            "\n",
            "Fold index: 7 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.52909372832252\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.5339086791528951\n",
            "\n",
            "Fold index: 8 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.6034215035339473\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.6034215035339473\n",
            "\n",
            "Fold index: 9 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (4069, 3)\n",
            "X_test: (452, 3)\n",
            "y_train: (4069,)\n",
            "y_test: (452,)\n",
            "\n",
            "Classifier evaluation for: Naive_Bayes\n",
            "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
            "Area under ROC curve: 0.63\n",
            "\n",
            "Classifier evaluation for: Logistic_Regression\n",
            "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
            "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False)\n",
            "Area under ROC curve: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Znz_82XowsKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "cv_results_df.columns = names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vr3h88cXw5LU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "f5585c1a-ed39-4fcc-8371-9dc186dce4b4"
      },
      "cell_type": "code",
      "source": [
        "print('\\n----------------------------------------------')\n",
        "print('Average results from ', N_FOLDS, '-fold cross-validation\\n',\n",
        "      '\\nMethod                 Area under ROC Curve', sep = '')     \n",
        "print(cv_results_df.mean())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------\n",
            "Average results from 10-fold cross-validation\n",
            "\n",
            "Method                 Area under ROC Curve\n",
            "Naive_Bayes            0.605224\n",
            "Logistic_Regression    0.606980\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8ZLdBLZiw8XZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "0134744b-8483-4128-f75f-6554ea21cd7e"
      },
      "cell_type": "code",
      "source": [
        "#from 10-fold cross validation result, we can see Logistic_regression has slightly larger area under ROC curve, so this is the method I recommend\n",
        "print(cv_results_df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Naive_Bayes  Logistic_Regression\n",
            "0     0.610340             0.610340\n",
            "1     0.574080             0.574080\n",
            "2     0.654569             0.654569\n",
            "3     0.587235             0.587235\n",
            "4     0.584457             0.584457\n",
            "5     0.653991             0.662918\n",
            "6     0.625050             0.628870\n",
            "7     0.529094             0.533909\n",
            "8     0.603422             0.603422\n",
            "9     0.630000             0.630000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "anc2Ds1Azgw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#now test all 8 combination of three binary variables (default, housing, loan), compare predict vs actual using first the recommended model - logistical regression\n",
        "\n",
        "my_default = np.array([1, 1, 1, 1, 0, 0, 0, 0], np.int32)\n",
        "my_housing = np.array([1, 1, 0, 0, 1, 1, 0, 0], np.int32)\n",
        "my_loan = np.array([1, 0, 1, 0, 1, 0, 1, 0], np.int32)\n",
        "\n",
        "my_X_test = np.vstack([my_default, my_housing, my_loan]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NNx3rEL62MwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "fca55d1e-f0bb-4fcf-9f34-260c21aaccb8"
      },
      "cell_type": "code",
      "source": [
        "# fit logistic regression to full data set\n",
        "clf = LogisticRegression()\n",
        "X_train = model_data[:, 0:model_data.shape[1]-1]\n",
        "y_train = model_data[:, model_data.shape[1]-1]\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "ljTOEomS2ZJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict specific test cases covering all situations\n",
        "y_my_test_predict = clf.predict_proba(my_X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbkznOI02fC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "900a81db-a25c-4a51-b902-1448491c3fad"
      },
      "cell_type": "code",
      "source": [
        "# create DataFrame for displaying test cases and predicted probabilities\n",
        "my_targeting_df = pd.DataFrame(np.hstack([my_X_test, y_my_test_predict]))\n",
        "my_targeting_df.columns = ['default', 'housing', 'loan', \n",
        "                           'predict_NO', 'predict_YES']\n",
        "print('\\n\\nLogistic regression model predictions for test cases:')\n",
        "print(my_targeting_df) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Logistic regression model predictions for test cases:\n",
            "   default  housing  loan  predict_NO  predict_YES\n",
            "0      1.0      1.0   1.0    0.945729     0.054271\n",
            "1      1.0      1.0   0.0    0.892349     0.107651\n",
            "2      1.0      0.0   1.0    0.900786     0.099214\n",
            "3      1.0      0.0   0.0    0.811988     0.188012\n",
            "4      0.0      1.0   1.0    0.953277     0.046723\n",
            "5      0.0      1.0   0.0    0.906588     0.093412\n",
            "6      0.0      0.0   1.0    0.914016     0.085984\n",
            "7      0.0      0.0   0.0    0.834890     0.165110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2J2RHfWqDRIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "group 3 & group 7 have largest predict_YES probability, so those are the best target marketing efforts\n",
        "\n",
        "Group 3: default = true, housing = false, loan = false\n",
        "\n",
        "Group 7, same as group 3 except default = false\n",
        "\n",
        "So, basically if the customer does not have mortgage and loan, no matter his credit default history, it has around 16~18% probability getting a term deposit.\n"
      ]
    },
    {
      "metadata": {
        "id": "jPytvzXDEm5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Out of curiosity, I want to take a look at the less preferred model: Naive Bayes classification to see what results it gets here..."
      ]
    },
    {
      "metadata": {
        "id": "8tVnyF1_2j8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf2=BernoulliNB(alpha=1.0, binarize=0.5, \n",
        "                           class_prior = [0.5, 0.5], fit_prior=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GhUUmcD4E9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "68fe9204-0d19-4482-b837-28423f17c1f7"
      },
      "cell_type": "code",
      "source": [
        "clf2.fit(X_train, y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "xH05jTXd4WMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_my_test_predict2 = clf2.predict_proba(my_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uI7cV904e9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "5286100c-2a6b-4f05-dc1e-c6e3ec5f4fb5"
      },
      "cell_type": "code",
      "source": [
        "my_targeting_df2 = pd.DataFrame(np.hstack([my_X_test, y_my_test_predict2]))\n",
        "my_targeting_df2.columns = ['default', 'housing', 'loan', \n",
        "                           'predict_NO', 'predict_YES']\n",
        "print('\\n\\nNaive Bayes model predictions for test cases:')\n",
        "print(my_targeting_df2) "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Naive Bayes model predictions for test cases:\n",
            "   default  housing  loan  predict_NO  predict_YES\n",
            "0      1.0      1.0   1.0    0.703288     0.296712\n",
            "1      1.0      1.0   0.0    0.529384     0.470616\n",
            "2      1.0      0.0   1.0    0.551965     0.448035\n",
            "3      1.0      0.0   0.0    0.368951     0.631049\n",
            "4      0.0      1.0   1.0    0.727746     0.272254\n",
            "5      0.0      1.0   0.0    0.559193     0.440807\n",
            "6      0.0      0.0   1.0    0.581473     0.418527\n",
            "7      0.0      0.0   0.0    0.397353     0.602647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RbdfnEGTE6LX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, so Naive Bayes model give the same suggestion as group 3 & group 7, however the predict_YES probability is largely overstated here."
      ]
    },
    {
      "metadata": {
        "id": "pecTxCwjFLGz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "below are just some practice.... I want to see if I just choose one binary variable here, default, what kind of performance/confusion matrix if I use that to predict whether client will subscribe term depoit. "
      ]
    },
    {
      "metadata": {
        "id": "DHAOJcVG4rup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a474b091-8a4b-4297-a720-c752b9d545f1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_clf=SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(model_data[:,0].reshape(-1,1),model_data[:,3])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
              "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
              "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
              "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
              "       tol=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "hNukooJA6bkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "85566516-a198-4959-aa90-c0ba520b98b5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "y_train_pred=cross_val_predict(sgd_clf,model_data[:,0].reshape(-1,1),model_data[:,3],cv=3)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tHeFtWwp8QzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d3be6358-2306-4e46-9adb-5bb4471231ba"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(model_data[:,3],y_train_pred)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4000,    0],\n",
              "       [ 521,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "zstEM6Ng8oAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "2040ec68-6fcf-4331-efc7-89e59c022c61"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "9vwN_xwB_z3z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6i0i0th2EiUV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I think since the customer with positive response to subscribe to term deposit  are very small part of the total population, that make the classification model (with three factors we chose) have very limited predict accuracy. we need to introduce more variable in order to improve the model here."
      ]
    }
  ]
}