{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict422 Week6 Kun Yang.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluebottle66/Practical-Machine-Learning-Northwestern-/blob/master/Predict422_Week6_Kun_Yang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XDUNC5M45HEK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 1: Retrieve data and preparation**"
      ]
    },
    {
      "metadata": {
        "id": "D0nwf6EH4vIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "227781e6-4806-4abd-c91a-fa7c0c8bd88c"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "\n",
        "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
        "WORK_DIRECTORY = \"/tmp/mnist-data\"\n",
        "\n",
        "def maybe_download(filename):\n",
        "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
        "    if not os.path.exists(WORK_DIRECTORY):\n",
        "        os.mkdir(WORK_DIRECTORY)\n",
        "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
        "        statinfo = os.stat(filepath)\n",
        "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "    else:\n",
        "        print('Already downloaded', filename)\n",
        "    return filepath\n",
        "\n",
        "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
        "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
        "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
        "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ASJ77lBW5WR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "68add21a-3d5a-410c-8f66-7225213810d8"
      },
      "cell_type": "code",
      "source": [
        "import gzip, binascii, struct, numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = 28\n",
        "PIXEL_DEPTH = 255\n",
        "\n",
        "def extract_data(filename, num_images):\n",
        "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
        "  \n",
        "    For MNIST data, the number of channels is always 1.\n",
        "\n",
        "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
        "    \"\"\"\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        # Skip the magic number and dimensions; we know these values.\n",
        "        bytestream.read(16)\n",
        "\n",
        "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
        "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
        "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
        "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "        return data\n",
        "\n",
        "train_data = extract_data(train_data_filename, 60000)\n",
        "test_data = extract_data(test_data_filename, 10000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FKGDIxjO5-fi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we retrieved all the data to train and test dataset, where data is desired formate:\n",
        "\n",
        "\n",
        "> data are stored with 28 * 28 dimension, rescaled to [-0.5,0.5]\n",
        "\n",
        "\n",
        "> train data have 60000 images and test data have 10000 images\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "eML3BG3K5ptk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "eb816a2e-075e-4e65-87d4-08b9de8d0d4c"
      },
      "cell_type": "code",
      "source": [
        "#take a look at our data to make sure it is what we need\n",
        "\n",
        "get_ipython().magic(u'matplotlib inline')\n",
        "\n",
        "print('Training data shape', train_data.shape)\n",
        "_, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(train_data[2].reshape(28, 28), cmap=plt.cm.Greys);\n",
        "ax2.imshow(train_data[3].reshape(28, 28), cmap=plt.cm.Greys);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAC4CAYAAAAscG03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2516173cf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "orT4pLjT7M2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6f0c1da3-3144-46f2-ccdb-4860238bb91f"
      },
      "cell_type": "code",
      "source": [
        "#ok, now get the label\n",
        "NUM_LABELS = 10\n",
        "\n",
        "def extract_labels(filename, num_images):\n",
        "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        # Skip the magic number and count; we know these values.\n",
        "        bytestream.read(8)\n",
        "        buf = bytestream.read(1 * num_images)\n",
        "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
        "    # Convert to dense 1-hot representation.\n",
        "    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
        "\n",
        "train_labels = extract_labels(train_labels_filename, 60000)\n",
        "test_labels = extract_labels(test_labels_filename, 10000)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eatqKbRA7mVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "69d4e0bc-af00-4f19-d735-6508d7d6c324"
      },
      "cell_type": "code",
      "source": [
        "print('Training labels shape', train_labels.shape)\n",
        "print('First label vector', train_labels[2])\n",
        "print('Second label vector', train_labels[3])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training labels shape (60000, 10)\n",
            "First label vector [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "Second label vector [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mf9Q8Why76p9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "the label shows digit 4 and 1 have value, it matched above data image with correct label, so this means we get our label and value all good"
      ]
    },
    {
      "metadata": {
        "id": "PARbqip28RLW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 2: segment dato into training, test and validation set**"
      ]
    },
    {
      "metadata": {
        "id": "Xiyd3w6M7tHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "defec229-4b93-4609-8d15-bae037fca9c8"
      },
      "cell_type": "code",
      "source": [
        "VALIDATION_SIZE = 5000\n",
        "\n",
        "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
        "validation_labels = train_labels[:VALIDATION_SIZE]\n",
        "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
        "train_labels = train_labels[VALIDATION_SIZE:]\n",
        "\n",
        "train_size = train_labels.shape[0]\n",
        "\n",
        "print('Validation shape', validation_data.shape)\n",
        "print('Train size', train_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation shape (5000, 28, 28, 1)\n",
            "Train size 55000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MwyTwHJZ8sr9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step3: defining our model**\n",
        "\n",
        "\n",
        "1.   define variables to hold weights\n",
        "2.   define model graph structure\n",
        "3.   stamping copies of model graph for training, testing and validation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YfVJ4k3q8myI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "BATCH_SIZE = 60\n",
        "NUM_CHANNELS = 1\n",
        "SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JK0lxPW9ql2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#placeholder for data\n",
        "\n",
        "train_data_node = tf.placeholder(\n",
        "  tf.float32,\n",
        "  shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pog8BiE-92tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#placeholder for label\n",
        "train_labels_node = tf.placeholder(tf.float32,\n",
        "                                   shape=(BATCH_SIZE, NUM_LABELS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1n2MP-8t97B4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For the validation and test data, we'll just hold the entire dataset in\n",
        "# one constant node.\n",
        "validation_data_node = tf.constant(validation_data)\n",
        "test_data_node = tf.constant(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z5iD015lCVRt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- first step: define variables"
      ]
    },
    {
      "metadata": {
        "id": "r-ctj6xn-dur",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# now define variables\n",
        "\n",
        "conv1_weights = tf.Variable(\n",
        "  tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "conv1_biases = tf.Variable(tf.zeros([32]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDRNszMG-v1y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv2_weights = tf.Variable(\n",
        "  tf.truncated_normal([5, 5, 32, 64],\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0k4-J2T8_GBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
        "  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8ufKdJ7ASAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc2_weights = tf.Variable(\n",
        "  tf.truncated_normal([512, NUM_LABELS],\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDifJrKwAW54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#look at the variable we just created\n",
        "from tensorflow.python.framework import ops\n",
        "All_variables_list = ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1KfFf7vkBbOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "568a0255-a8a5-475c-aa6b-520b720cd4ef"
      },
      "cell_type": "code",
      "source": [
        "print(All_variables_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_2:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_3:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_4:0' shape=(3136, 512) dtype=float32_ref>, <tf.Variable 'Variable_5:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'Variable_6:0' shape=(512, 10) dtype=float32_ref>, <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rGrULebqCbRJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- second step: define graph structure"
      ]
    },
    {
      "metadata": {
        "id": "YBai9RO1Bkqe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(data, train=False):\n",
        "    \"\"\"The Model definition.\"\"\"\n",
        "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
        "    # the same size as the input). Note that {strides} is a 4D array whose\n",
        "    # shape matches the data layout: [image index, y, x, depth].\n",
        "    conv = tf.nn.conv2d(data,\n",
        "                        conv1_weights,\n",
        "                        strides=[1, 1, 1, 1],\n",
        "                        padding='SAME')\n",
        "\n",
        "    # Bias and rectified linear non-linearity.\n",
        "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
        "\n",
        "    # Max pooling. The kernel size spec ksize also follows the layout of\n",
        "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
        "    pool = tf.nn.max_pool(relu,\n",
        "                          ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1],\n",
        "                          padding='SAME')\n",
        "    conv = tf.nn.conv2d(pool,\n",
        "                        conv2_weights,\n",
        "                        strides=[1, 1, 1, 1],\n",
        "                        padding='SAME')\n",
        "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
        "    pool = tf.nn.max_pool(relu,\n",
        "                          ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
        "    # fully connected layers.\n",
        "    pool_shape = pool.get_shape().as_list()\n",
        "    reshape = tf.reshape(\n",
        "        pool,\n",
        "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
        "  \n",
        "    # Fully connected layer. Note that the '+' operation automatically\n",
        "    # broadcasts the biases.\n",
        "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
        "\n",
        "    # Add a 50% dropout during training only. Dropout also scales\n",
        "    # activations such that no rescaling is needed at evaluation time.\n",
        "    if train:\n",
        "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
        "    return tf.matmul(hidden, fc2_weights) + fc2_biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZgflGuzDT1G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- step3: stamp out multiple copies for traing, testing and validation"
      ]
    },
    {
      "metadata": {
        "id": "HevHPn9aC5oA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "388fa0dd-4dea-49ea-dce0-be7cbcc32c45"
      },
      "cell_type": "code",
      "source": [
        "# Training computation: logits + cross-entropy loss.\n",
        "logits = model(train_data_node, True)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "  labels=train_labels_node, logits=logits))\n",
        "\n",
        "# L2 regularization for the fully connected parameters.\n",
        "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
        "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
        "# Add the regularization term to the loss.\n",
        "loss += 5e-4 * regularizers\n",
        "\n",
        "# Optimizer: set up a variable that's incremented once per batch and\n",
        "# controls the learning rate decay.\n",
        "batch = tf.Variable(0)\n",
        "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
        "learning_rate = tf.train.exponential_decay(\n",
        "  0.01,                # Base learning rate.\n",
        "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
        "  train_size,          # Decay step.\n",
        "  0.95,                # Decay rate.\n",
        "  staircase=True)\n",
        "# Use simple momentum for the optimization.\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
        "                                       0.9).minimize(loss,\n",
        "                                                     global_step=batch)\n",
        "\n",
        "# Predictions for the minibatch, validation set and test set.\n",
        "train_prediction = tf.nn.softmax(logits)\n",
        "# We'll compute them only once in a while by calling their {eval()} method.\n",
        "validation_prediction = tf.nn.softmax(model(validation_data_node))\n",
        "test_prediction = tf.nn.softmax(model(test_data_node))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-85183e4c5a6f>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q-MLRHWmD5-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training and Visualization of the results**"
      ]
    },
    {
      "metadata": {
        "id": "fUC4bsj0Dx2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a new interactive session that we'll use in\n",
        "# subsequent code cells.\n",
        "s = tf.InteractiveSession()\n",
        "\n",
        "# Use our newly created session as the default for \n",
        "# subsequent operations.\n",
        "s.as_default()\n",
        "\n",
        "# Initialize all the variables we defined above.\n",
        "tf.global_variables_initializer().run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkQZavYhEM4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d80f8c2d-979c-4478-bc15-f5d194642d46"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 60\n",
        "\n",
        "# Grab the first BATCH_SIZE examples and labels.\n",
        "batch_data = train_data[:BATCH_SIZE, :, :, :]\n",
        "batch_labels = train_labels[:BATCH_SIZE]\n",
        "\n",
        "print(batch_data.shape)\n",
        "print(batch_labels.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60, 28, 28, 1)\n",
            "(60, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "awC-MDHQE1Iv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feed_dict = {train_data_node: batch_data,\n",
        "             train_labels_node: batch_labels}\n",
        "\n",
        "# Run the graph and fetch some of the nodes.\n",
        "_, l, lr, predictions = s.run(\n",
        "  [optimizer, loss, learning_rate, train_prediction],\n",
        "  feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3B5aDJbqFUsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "1ba27321-eee1-4288-9a28-40e190abf32a"
      },
      "cell_type": "code",
      "source": [
        "print(predictions[0])\n",
        "print('First prediction', numpy.argmax(predictions[0]))\n",
        "print(predictions.shape)\n",
        "print('All predictions', numpy.argmax(predictions, 1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.2539226e-04 4.7622027e-05 1.6686729e-03 5.6782723e-05 6.0343301e-01\n",
            " 4.3496866e-02 2.1931728e-05 1.4128604e-04 1.5490332e-05 3.5089296e-01]\n",
            "First prediction 4\n",
            "(60, 10)\n",
            "All predictions [4 4 2 7 7 7 7 7 7 7 7 7 0 8 9 0 7 7 0 7 4 0 5 0 9 9 7 0 7 4 7 7 7 0 7 7 9\n",
            " 7 9 9 0 7 7 7 2 7 0 7 2 9 9 9 9 9 0 7 9 4 8 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nrkyPVuXFilY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "1e01a788-8e42-4c6d-c255-d8decdcf0a24"
      },
      "cell_type": "code",
      "source": [
        "print('Batch labels', numpy.argmax(batch_labels, 1))\n",
        "correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(batch_labels, 1))\n",
        "total = predictions.shape[0]\n",
        "\n",
        "print(float(correct) / float(total))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch labels [7 3 4 6 1 8 1 0 9 8 0 3 1 2 7 0 2 9 6 0 1 6 7 1 9 7 6 5 5 8 8 3 4 4 8 7 3\n",
            " 6 4 6 6 3 8 8 9 9 4 4 0 7 8 1 0 0 1 8 5 7 1 7]\n",
            "0.06666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qXf7poDeF8gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "1bce1c5f-8abe-48c1-82d9-2d272a4c1146"
      },
      "cell_type": "code",
      "source": [
        "confusions = numpy.zeros([10, 10], numpy.float32)\n",
        "bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(batch_labels, 1))\n",
        "for predicted, actual in bundled:\n",
        "  confusions[predicted, actual] += 1\n",
        "\n",
        "plt.grid(False)\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.yticks(numpy.arange(NUM_LABELS))\n",
        "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD4CAYAAADb7cuFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2516afd940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7L70ky2pGUeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Above shows using the first 60 data to traint the model, the result is very bad. we can compare between our predict vs label to see how far the predication is from the correct value. the correation ratio is only 6%"
      ]
    },
    {
      "metadata": {
        "id": "54zxwF9vGCvl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#wrap above into a function\n",
        "def error_rate(predictions, labels):\n",
        "    \"\"\"Return the error rate and confusions.\"\"\"\n",
        "    correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1))\n",
        "    total = predictions.shape[0]\n",
        "\n",
        "    error = 100.0 - (100 * float(correct) / float(total))\n",
        "\n",
        "    confusions = numpy.zeros([10, 10], numpy.float32)\n",
        "    bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(labels, 1))\n",
        "    for predicted, actual in bundled:\n",
        "        confusions[predicted, actual] += 1\n",
        "    \n",
        "    return error, confusions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3XWcE8aHtNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "6e086ad1-baad-44ee-d020-0ecab7fcd3a8"
      },
      "cell_type": "code",
      "source": [
        "steps = train_size // BATCH_SIZE\n",
        "print(train_size)\n",
        "print(BATCH_SIZE)\n",
        "print(steps)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55000\n",
            "60\n",
            "916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h4SV5i35GIgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "d824a7fe-0f31-4896-9b8e-3b2cc99f3261"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for step in range(steps):\n",
        "    # Compute the offset of the current minibatch in the data.\n",
        "    # Note that we could use better randomization across epochs.\n",
        "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
        "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
        "    # This dictionary maps the batch data (as a numpy array) to the\n",
        "    # node in the graph it should be fed to.\n",
        "    feed_dict = {train_data_node: batch_data,\n",
        "                 train_labels_node: batch_labels}\n",
        "    # Run the graph and fetch some of the nodes.\n",
        "    _, l, lr, predictions = s.run(\n",
        "      [optimizer, loss, learning_rate, train_prediction],\n",
        "      feed_dict=feed_dict)\n",
        "    \n",
        "    # Print out the loss periodically.\n",
        "    if step % 100 == 0:\n",
        "        error, _ = error_rate(predictions, batch_labels)\n",
        "        print('Step %d of %d' % (step, steps))\n",
        "        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))\n",
        "        print('Validation error: %.1f%%' % error_rate(\n",
        "              validation_prediction.eval(), validation_labels)[0])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 of 916\n",
            "Mini-batch loss: 7.71259 Error: 91.66667 Learning rate: 0.01000\n",
            "Validation error: 88.9%\n",
            "Step 100 of 916\n",
            "Mini-batch loss: 3.28615 Error: 5.00000 Learning rate: 0.01000\n",
            "Validation error: 5.5%\n",
            "Step 200 of 916\n",
            "Mini-batch loss: 3.29361 Error: 8.33333 Learning rate: 0.01000\n",
            "Validation error: 3.7%\n",
            "Step 300 of 916\n",
            "Mini-batch loss: 3.19405 Error: 3.33333 Learning rate: 0.01000\n",
            "Validation error: 3.4%\n",
            "Step 400 of 916\n",
            "Mini-batch loss: 3.07051 Error: 1.66667 Learning rate: 0.01000\n",
            "Validation error: 2.6%\n",
            "Step 500 of 916\n",
            "Mini-batch loss: 3.02596 Error: 1.66667 Learning rate: 0.01000\n",
            "Validation error: 2.4%\n",
            "Step 600 of 916\n",
            "Mini-batch loss: 3.05108 Error: 3.33333 Learning rate: 0.01000\n",
            "Validation error: 1.8%\n",
            "Step 700 of 916\n",
            "Mini-batch loss: 3.11480 Error: 6.66667 Learning rate: 0.01000\n",
            "Validation error: 2.0%\n",
            "Step 800 of 916\n",
            "Mini-batch loss: 3.09262 Error: 6.66667 Learning rate: 0.01000\n",
            "Validation error: 1.9%\n",
            "Step 900 of 916\n",
            "Mini-batch loss: 2.85356 Error: 0.00000 Learning rate: 0.01000\n",
            "Validation error: 2.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7DkSZTOVI-yp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see after we go through the 916 steps to train, the erro rate is going down a lot. for our validation set, the error is at 2%. Next we can try how our model performs on our testing set."
      ]
    },
    {
      "metadata": {
        "id": "2zx92RKxIG4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "181afa79-31e3-4e5f-c880-6e1b75556a1b"
      },
      "cell_type": "code",
      "source": [
        "test_error, confusions = error_rate(test_prediction.eval(), test_labels)\n",
        "print('Test error: %.1f%%' % test_error)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test error: 2.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qJ6vN4vzJnT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "matching the performance with our validation set"
      ]
    },
    {
      "metadata": {
        "id": "qstVkklZJi46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "5d9ecc40-e549-4ca6-b7d0-9d40e314b51e"
      },
      "cell_type": "code",
      "source": [
        "#take a look at our plots\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(False)\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.yticks(numpy.arange(NUM_LABELS))\n",
        "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
        "\n",
        "for i, cas in enumerate(confusions):\n",
        "    for j, count in enumerate(cas):\n",
        "        if count > 0:\n",
        "            xoff = .07 * len(str(count))\n",
        "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEGCAYAAACO3ptGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKbQRKKXQRqCUAv4/e5BEdLN53KYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2516afd668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0MGHY5_XJ9ra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks like the mispredictions are mostly between '2' adn '7'; '5' and '3'; '5' and '6'; '5' and '8'"
      ]
    },
    {
      "metadata": {
        "id": "n1gJSK2oJ3R7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "8db9e584-2f83-41f8-92ad-d7931c5674a2"
      },
      "cell_type": "code",
      "source": [
        "#take a look how the histogram looks like for the labels in our test set\n",
        "\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.hist(numpy.argmax(test_labels, 1));"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TCGfSSVDiDXpIK9784jQDe9t4CpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f25046df400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rpIcYk3HKXf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "f418e803-d99d-4852-f83d-77ca54022355"
      },
      "cell_type": "code",
      "source": [
        "#try rerun our training to see whether our model will improve\n",
        "for step in range(steps):\n",
        "    # Compute the offset of the current minibatch in the data.\n",
        "    # Note that we could use better randomization across epochs.\n",
        "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
        "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
        "    # This dictionary maps the batch data (as a numpy array) to the\n",
        "    # node in the graph it should be fed to.\n",
        "    feed_dict = {train_data_node: batch_data,\n",
        "                 train_labels_node: batch_labels}\n",
        "    # Run the graph and fetch some of the nodes.\n",
        "    _, l, lr, predictions = s.run(\n",
        "      [optimizer, loss, learning_rate, train_prediction],\n",
        "      feed_dict=feed_dict)\n",
        "    \n",
        "    # Print out the loss periodically.\n",
        "    if step % 100 == 0:\n",
        "        error, _ = error_rate(predictions, batch_labels)\n",
        "        print('Step %d of %d' % (step, steps))\n",
        "        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))\n",
        "        print('Validation error: %.1f%%' % error_rate(\n",
        "              validation_prediction.eval(), validation_labels)[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 of 916\n",
            "Mini-batch loss: 3.00177 Error: 6.66667 Learning rate: 0.00950\n",
            "Validation error: 2.2%\n",
            "Step 100 of 916\n",
            "Mini-batch loss: 2.94567 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 1.7%\n",
            "Step 200 of 916\n",
            "Mini-batch loss: 2.89360 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 1.6%\n",
            "Step 300 of 916\n",
            "Mini-batch loss: 2.83109 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 1.5%\n",
            "Step 400 of 916\n",
            "Mini-batch loss: 2.82303 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 1.5%\n",
            "Step 500 of 916\n",
            "Mini-batch loss: 2.73074 Error: 0.00000 Learning rate: 0.00950\n",
            "Validation error: 1.4%\n",
            "Step 600 of 916\n",
            "Mini-batch loss: 2.74509 Error: 1.66667 Learning rate: 0.00950\n",
            "Validation error: 1.6%\n",
            "Step 700 of 916\n",
            "Mini-batch loss: 2.81013 Error: 6.66667 Learning rate: 0.00950\n",
            "Validation error: 1.5%\n",
            "Step 800 of 916\n",
            "Mini-batch loss: 2.70353 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 1.4%\n",
            "Step 900 of 916\n",
            "Mini-batch loss: 2.61659 Error: 0.00000 Learning rate: 0.00950\n",
            "Validation error: 1.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r7kTZ24MMmIl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, with another round of training, we can see the validation error is further reduced to 1.3%. we can see how our model performs with testing set again"
      ]
    },
    {
      "metadata": {
        "id": "dcKophYRKzJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e46396cd-ea7d-492c-c41b-0e62a24f1d9a"
      },
      "cell_type": "code",
      "source": [
        "test_error, confusions = error_rate(test_prediction.eval(), test_labels)\n",
        "print('Test error: %.1f%%' % test_error)\n",
        "\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(False)\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.yticks(numpy.arange(NUM_LABELS))\n",
        "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
        "\n",
        "for i, cas in enumerate(confusions):\n",
        "    for j, count in enumerate(cas):\n",
        "        if count > 0:\n",
        "            xoff = .07 * len(str(count))\n",
        "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test error: 1.5%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEGCAYAAACO3ptGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VOX1x/HPhMWERUggAZFFTOnJ\nT7GgggbZBFpQXAIYQUSJFlGUUgq0oVar2NYuylqsldbIoqUhRkOjRi0ERKylqGAFLEeIIJFFIlQK\nBpBAfn/cQYMmZMjcJ8nAeb9eeTF3mDn3yc3k5N5n7v1OoLS0FGPMmS2qpgdgjKl51giMMdYIjDHW\nCIwxWCMwxgB1a3oAX7oo4OTti8D6B12UNU7Vc1T3iKO6kaO0dEqgvPttj8AYY43AGGONwBiDNQJj\nDNYIjDFYIzDGYI3AGIPj8whEZAaQDJQC41X1LZfrM8ZUjbM9AhHpDXRQ1W7AKOD3rtZljAmPyz2C\nfsBiAFX9j4jEisjZqvq/Sp95Tlt44AnYvw+KD8CH78Olvbz/a30+/PUxyP6ztzzsbhgwFL7fx9X3\ncUri4xuSkXE9hw6VEBsbw4gRz7F79+c1PaxqFwgEmDAhmXvv7UlS0mPs2VMcdk2RZjz6aD927TpA\nfHwDfvjDv1NYWPnLqTKufmYuXwsDB3Zg9uyBJCbO8qWeyzmClkBRmeWi4H2Vu3kcZD4O6cOhsAC2\nbITxg2HSUNi+FV542ntcm0SQTj4POzydOrVgxoxVDB36LHl5m0hJSarpIdWI+PgGrFmzk/Xrd/tW\nc8CA83nllQLuvDOPZcu20rt3W1/quvqZuaobGxtDWlpnCgv3+VIPqneysNxznMt1qBiaxHm3o6Ig\n8ULv9s3jYPFcOHwIAgGY8DuY9TMHQ626pUs/ZPnyLURFBejVqx0rV35U00OqEbt3f85rr231teb8\n+e9xxx2dWbRoMCNGdOT559WXuq5+Zq7qTp3an/vuy8fPcDGXjWAHJ+4BtAJ2hvTMBdPhkp7wiwxo\n2Qa+OAR16kCf62HZYu8xaZPgxWdg316/xx225s0bsHDhDcycuYqNGz+t6eGcNsaO7cL06f9i2LAc\nZs9+m3HjuvhW29XPzO+6qakXsG7dJ2ze7O/r3mUj+DuQCiAilwA7VHV/SM+MjYf50+CBUXC0BNat\nhsv6wrtvfvWYbt+Dvinwq7nQPgmGjHLwLZy6Jk2iychIIT19CStWbK3p4ZxW4uKi2bPnIAB79x4k\nIaGhL3Vd/cxc1B00KInOnVsyd+4gkpKaM3lyD1/qBlyGl4rIb4FewDFgrKr+u8IHl70MuWUb+M3T\nsLcItm3ydv9vGQ8H/ucdGnzdU8srnCys7suQp0y5kpSUJLZu/QyAxYs3Mn/+u9U6htogObk1kyf3\noEePtqxevZ3cXGXOnLdDfHb5lyG3a9eEWbP6U1RUTLNmMUyYsISPPjqV4+TyL0N29TNz/VpYvvw2\n+vSZd0rPqegyZKeN4JRYHoH5kuURuGJ5BMaYClkjMMZYIzDGWCMwxmCNwBhDLUoxdjW7/yAPOan7\nEPZuhDs2u1/dbI/AGGONwBhjjcAYgzUCYwzWCIwxWCMwxmCNwBiD40YgIh1FpEBEfuByPcaY8LhM\nMW4IzAbyXa3DGOMPl3sEh4GBeJFlNS4QCNBt4kTSi4po0KzZN5YB4hITGZGXx9DsbNLy84lLTCz3\ncScTH9+Q3NzhZGXdyJIlI31L0TGQmBhHXt4IsrOHkp+fRmJinK/1Bw7sQEHBeN/qBQIBJk7sRlFR\nOs2aNfClpqtt4KwRqGqJqh50Vf9UNYiPZ+eaNexev77cZYC60dG8OGYMWampbFm2jDbdu5f7uJOx\nFGN3oqPrMmbMi6SmZrFs2Ra6d2/jW20XycAukpxdbYMzZrLw89272fraaxUuA+zesAFKS0nLz6d9\n376sz8ws93EnYynG7mzYsJvSUsjPT6Nv3/ZkZobWnEPhIhnYRZKzq21wxjSCUO0rLGR+v368n51N\nt4kTq1TDUozdKSzcR79+88nOfp+JE7v5UtNVMrArLraBNYIyuqenk9i/PwD7d+wgJu7Uj78sxdid\n9PTu9O+fCMCOHfuJi4vxpa6rZGAXXG0DZ+GlInIpMA04D++60u3AEFUtt+0GAlOcDOT4Zcitk5Pp\nMXkybXv0YPvq1Xy0ciWtL7/8y2XNzeWDl17iujlzOFJcTP3GjXlh9Ggan3vuCc/T3FzenjOnwsuQ\nLcXYndatz2bOnOsoLj5C48b1GT36BV+P6aFqycAVCS/JuXzhboNan2LsuhH4zfIITCSyFGNjTIWs\nERhjrBEYY6wRGGOwRmCMoRalGLvianb/0zr+vxvR/Ki9E+GWP++5n6jWnEUfFtsjMMZYIzDGWCMw\nxmCNwBiDNQJjDNYIjDFYIzDG4Pg8AhF5BOgZXM9vVPV5l+szxlSNyxTjPkBHVe0GXAXMdLUuY0x4\nXB4avA7cGLz9GdBQROpUpZCLNFjf6gYCRE+YSOyuIgLNmkF0NI0ys2i0MJPGz+UQaNqUQHw8jRfn\n0igzi8avLiGQkPDN51XHWKuxbiQIBGDixK4UFY2jWbMYoqPrkpWVQmbm9eTkDKZp07PCrB8529Zl\nivFRVf08uDgKyFPVo1Wp5SIN1q+6gfh4Stau4egGL0TyrNtup+SNlRy4+SYOP5dN9N33ULdTJw7O\nmsGBm4Zy5OU86l+f8o3nVcdYq7NuJPC+909Yv97Llbz99otYufJjbropl+xs5Z57LvGhfmRsW+eT\nhSKSgtcIqvxpRy7SYP2qW7p7NyVlUo7rfqcTJWvXAHD03bXU6XwxR5YupWT5coiKol7PXpS8sfIb\nz6uOsVZn3Uiwe3cxr7227cvlTp0SWLNmFwBr1+7m4otbhFk/crat6488GwDcB1ytqv6Gy9VWpaUQ\nFXXiMhBo3pxGzyzk4O9ncnTjxhoanDmZ0tJSoqICJyyfKVxOFjYBHgWurSiw9HRU8u5a6na9DIC6\nXbpS8tZqAk2a0OjPGRT/NJ2SFStqeISmImvXfsJll7UCoGvXlqxevbOGR1R9XO4RDAOaA1ki8lrw\nq21VCiUntyYn5yY6dkxgwYLB3HVXF18G6EfdusnJNH4uhzoXdqTRvAUQCFD30i40WvQs9QZew6E5\nTxD9owlEtWlLwxmzaPxcDmeNTPvG88668y7nY63OupEgObkVOTmD6dixOQsWXEMgEKBLl5Y8++wg\nrrkmkSeeCC99OpK27WmfYuyK5RFEIssjsBRjY0yFrBEYY6wRGGOsERhjOAPCS11xMbFX2srNx7MF\ndtgkpCeyJvaqk+0RGGOsERhjrBEYY7BGYIzBGoExBmsExhisERhjcHgegYg0AOYBLYBo4Jeq+qKr\n9Rljqs7lHsF1wNuq2hsYCkx3uC5jTBic7RGo6qIyi22Aj12tyxgTnurILHwTWAj8yPW6TpWLlNn4\n+Ibk5g4nK+tGliwZSUJCw6oXO7ctPJ0Hj/8VHv0zdLwYFr4KTyyCn/7ae8xPH4aMHO/rjU3Q63u+\nfB/hSEyMIy9vBNnZQ8nPTyMxMa6mh3RSkZQQ7WqszhuBql4BXA88IyLlhiLUFBcps506tWDGjFUM\nHfoseXmbSElJqnqx74+DBY/DPcPhowLIXAq/mARjhkHTWOjwf/Db+2DUYPjxKPjPe/D6Et++l6qK\njq7LmDEvkpqaxbJlW+jevU1ND+mkIikh2tVYXWYWXioibQBU9V28w5B4V+urChcps0uXfsjy5VuI\nigrQq1c7Vq78qOrFDhZD0+Bf06goiI4ps1wH5MKvHjvhQZj1q6qvy0cbNuymtBTy89Po27c9mZmh\nRbbXlEhKiHY1Vpd7BL2ASQAi0gJoBHzqcH21RvPmDVi48AZmzlzFxo1hfMt/mg6X9YRpGdCqDTz2\na7h5tHeYENMADh/yHhfXHNqcB+vX+jJ+PxQW7qNfv/lkZ7/PxIndano4phIuG8ETQIKIrAReAsaq\n6jGH66sVmjSJJiMjhfT0JaxYsTW8Ys3iYc40mDQKSkpgxd/ht/fCT0Z7jeD4L/7VgyH/pbDH7pf0\n9O70758IwI4d+4mLc5EVaPzk8l2Dg8DNrur7ITm5NZMn9/gyZTY3V5kz5+2wak6YkEzbtk2YNetq\nABYv3sj8+VVMwz18GH7/JOwtgg83wZEj8NhC+O8e+Mcy2Lnde9y3L4C/54Y1bj8tXLiOOXOuY/To\nS2ncuD6jR79Q00M6KRevA1d1XY3VUoxrEQsmMa5ZirExpkLWCIwx1giMMdYIjDFYinGt4mpSr7Sj\no0nI9TYJ6U69al2b7REYY06+RyAix4CK3tYrUdWz/B+SMaa6VXZoUA8IAPcB7wHLgDrA94Bvux2a\nMaa6nLQRqOpRABG5UlXLHmguEpGXnY7MGFNtQp0sbCgidwFvAMeAK4AEZ6MyxlSrUBvBLcCDwFi8\nQ4UNwEhXgzLGVK+QGoGqfiAitwItVHWn4zEZY6pZSG8fikg/oABYHlyeISLXhvC8GBEpEJHbwhql\nMcapUM8jeBhIBnaWWb4/hOfdD+ytwriMMdUo1EZwQFU/Ob6gqp8CX5zsCSKSBFyAF0piaotz2sIf\n8+CRv8KUP8PICTArx/t67t+QOvqrxw67G55aXnNj/RpXwZ2uuBivSDNyc4fypz8NJCcnlTZtzval\nbqiN4KCI9AYCIhIrIncDhyp5zjRgYlijM/67eRxkPg7pw6GwALZshPGDYdJQ2L4VXnjae1ybRJBO\nNTrUr3MV3OmKi/EOGHA+r7xSwJ135rFs2VZ6927rS91QG8E9wE+ArsBm4CpgdEUPFpGRwD9VdUvY\nIzT+OlQMTcoEoiYGA1BvHgeL53o5iIEATPgdzPpZzY2zHK6CO11xMd7589/jjjs6s2jRYEaM6Mjz\nz6svdUN9+zBRVU+YHBSRQUBFEb3XAOcHJxRbA4dF5GNVXVr1oRpfLJgOk6ZCl95w5Aso2AB16kCf\n6+H2K73HpE2CF5+BfTa9U9uMHduF6dP/xTPPrGfEiI6MG9eF3/3un2HXrexag/OARGCqiEzEO4cA\nvFOPZwKLy3ueqg4rU2MKsNWaQC0RGw/zp3mHBD+bDetWw2V94d03v3pMt+/Bty6EvinQPgmGjILn\nM2puzOZLcXHRrF27C4C9ew9yySUtfalb2R7BOcAw4DzggTL3H8NLKTaR5ovD8JtgIOq2TV4juGU8\nfLTpq8fcNeCr208trzVNwFVwpysuxjt79tvMmtWfIUOSaNYshgkT/PlAm5DCS4OHAX9T1dLgcl1V\nLfFlBMcHYuGlzlgeQSRyk0dQWnpfWOGldYGyedlviEhq2KMyxtQKoTaCiXjXGxzXn+CnGBljIl+o\njSCgqvuOL6jq//DmCYwxp4FQ3z58W0QWAa/hNY+rgHdcDcoYU71CbQQ/BEYAl+NFl/0FyHI1KGNM\n9arsPIJzgpcdtwfeDH4ddx7wobuhnYnczBS7mt0vTXf0bsQjv3VSFw46qOkqbfiIo7rlq2yPYBre\nB5nml/N/pcD5vo/IGFPtKsssvDn4b/vqGY4xpiZUdmjw1Mn+X1W/7+9wjDE1obK3D/8R/DoGxAH/\nBtYDLYBit0MzxlSXyg4NMgBEZIiqXnP8fhGZAeQ4HpsxppqEekJRWxFpWma5MTZRaMxpI9TzCP4I\nbBaRLXjvFrTHyy00xpwGQo0zf1xEngG+hZdJUKCqn53sOSJyJfAs3mcgAKxT1XFhjNUY40hIjUBE\nYoGfAeeo6i0icp2IrFLVokqeukJV7SpFY2q5UOcIngQK8Q4JAM4C5jsZUTWJj29Ibu5wsrJuZMmS\nkSQkNKzpIZ1UWtp3WLduNDk5qeTkpHLRRbXsE+fiBdJy4YY/wcgcaN/zxOWmbaDzcO/2yBwY+08Y\nEPrRZSAAEyd2pahoHM2axRAf34Dc3BvIykphyZJhJCRUPSU4ktKGjxs4sAMFBeN9qxdqI4hX1d8T\njDBX1WwglC12gYjkisgbIvK9qg7ShU6dWjBjxiqGDn2WvLxNpKQk1fSQKjVv3nsMHpzN4MHZrFtX\ny5J8vz0APngFnrsTNi+DxD4nLrfvDe/+FRYM9r4+2wb/mBVyeS8R+BPWr/8UgE6dEpgx4y2GDv0b\neXkfkpLSocpDj6S0YYDY2BjS0jpTWLiv8geHKNRGgIjUw5soRERaAJX9Cd0EPASkAGlAhojUr+I4\nfbd06YcsX76FqKgAvXq1Y+XKinJYa49rr+3A009fz1NPXUvTptE1PZwTvTMfut4BIxbBxSNg9ZMn\nLq9//qvHdhwCH/0TDoT+i7d7dzGvvbbty+WlS7eyfPm24M+vNStXflzloUdS2jDA1Kn9ue++fEII\nFwtZqI3gMeAt4EIRycU7sWjqyZ6gqttVdZGqlqpqAbALODes0fqsefMGLFx4AzNnrmLjxk9rejgn\nlZe3mbS0XG69NZc33ihkwoTLanpIJ+o2FlZOh78Mgzdnw6W3nbjcvcw88RU/gH8+HvYqmzePYeHC\n65g58202btwTdj0/HU8bHjYsh9mz32bcuC6+1E1NvYB16z5h82Z/E6ZDagSqmgVcC/wAb77gYlVd\ndLLniMgIEflx8HZLvLMRt4c3XP80aRJNRkYK6elLWLFia00Pp1KdO7egXr06AOzbd5j69evU8Ii+\npkEcFAd/GYv3QsPmJy43Cs5pNO8A+3fB0ZN+UFalmjQ5i4yMq0lPf40VKwrDquVCXFw0e/Z4Vzvu\n3XvQtzmoQYOS6Ny5JXPnDiIpqTmTJ/fwpW6o4aWLykaUh0JEGgMLgaZAfeAhVc2rcCDVHF46ZcqV\npKQksXWr9y7o4sUbmT//3eocQjkqvqT1oosSmDq1H/v2HSYmpi6jR+exa9eBEOu6uaT1hMuQY9vB\ndbPg8yJo0AxenPDN5f9+BBekwLmXwJKKL40u7zLk5ORWTJ58OT16tGb16p1cemlLdu48wNat3nHy\n4sWbmD9/fSUjLv8y5ONpwz16tGX16u2nmDZc/s+sXbsmzJrVn6Ki4i/Thj/66FSO6Sv/mS1ffht9\n+sw7hZpQWjql3PDSUBvBb4EP8PIIvmzlqupbHoGlGEOkXdtueQQQcT+zChpBqGcWDsObKCxbxPII\njDlNVHYZ8tl4H22+HngdmKmq1RudYoxxrrLJwuNTu3OA/wN+7nY4xpiaUNmhwXmqeguAiLxM+ZFl\nxpgIV9kewZeHAap6lOAJRcaY00tlewRf/8W3RuBUZE2/BB5xlI48+KdO6gZyXIw3sn5mFamsEVwh\nItvKLCcElwNAqar6dwK1MabGVNYIpFpGYYypUZVlFtb+K3GMMWEL+epDY8zpyxqBMcYagTHGGoEx\nhtAvOqoSERkBpAMlwAOq+pLL9RljqsbZHoGINAMeBHrghZqkuFqXMSY8Lg8NvgssVdX9qrpTVe+s\naiEXKbPG42rb+lY3vi3cnwcT/wr3/BmkGzzwKvwkG37+CjSKgyYJcO/fYFImTFgIdZzu6J6WXDaC\n84AGwRTjlSLSr6qFXKTMGo+rbetb3YHj4JXHYfpw2FUAnb7n3X40FfYUQtuOcP0kWPokTLsJCjdA\n96H+fBNnEJeNIAA0A4YAtwFzRaTcdJTKuEiZNR5X29a3uoeLvb/6AIEob7lFe/jNm1C/Abz/OpzX\nCT5c4z1my1pof3H46z3DuGwEnwBvqmpJMMV4PxDvcH3mdJQ7HS7oCWMzoHkbOHIICt6Be6+APR9D\nj5uAUq9JHOdnzvcZwmUj+DvQV0SighOHjYDanRluap8m8fC3afCHUXC0BC4ZCG0u8P7vvzu8vYUP\n10KHYLz7t7rCptU1N94I5awRqOp2IBtYBbwMjFPVY1WplZzcmpycm+jYMYEFCwZz113+ZMQbd9vW\nt7pHDsOYJ+Anz8LB/fD0ZLh9hjdZeFE/WPE0vDAdet/qPSa+Hfzr+crrmhOElGJcHSzF2BxXOthR\nOrKTPILIUlGKsZ1ZaIyxRmCMsUZgjMEagTEGawTGGBxffWhMVbia3T8W5/+7EVF7T493ImyPwBhj\njcAYY43AGIM1AmMM1giMMVgjMMbg8O1DERkF3Frmri6q2sjV+owxVeesEahqBpABICK9AcuPMqaW\nqq4Tih4ARlTTuowxp8j5HIGIdAUKVXVXVWtEUopxfHxDcnOHk5V1I0uWjCQhoWGtrnvGCQTgnonw\nQRHENYPoaHgqC57MhKdzoEnT8u9rnwiL8mBeNizO95YrXZW71+3AgR0oKBjvW73qmCy8A5gXToFI\nSjHu1KkFM2asYujQZ8nL20RKSlKtrnvGaR4P762B/6z3lm++HVathDtugtxsGHVP+fedFQ2TxsBt\nqbByGVzevdJVuXrdxsbGkJbWmcLCfb7VrI5GcCXwZjgFIinFeOnSD1m+fAtRUQF69WrHypX+fLK8\nq7pnnKLd8MZrXy1f2An+HUxAfm8tXHRx+fdt3OCFoi7Oh5594fnMSlfl6nU7dWp/7rsv39eMVqeN\nQERaAQdU9QuX66ltmjdvwMKFNzBz5io2bvQvr9VV3TNaaSlEfS0Bubz7ALYXwqB+3l7CPROrd5xB\nqakXsG7dJ2zevNfXuq73CM4Bav/+vI+aNIkmIyOF9PQlrFixtdbXPeOtWwuXBBOQL+kKa1aXf98P\n06FPf+++XTugaVyNDHfQoCQ6d27J3LmDSEpqzuTJPXypGxHhpcnJrZk8uQc9erRl9ert5OYqc+a8\nXZ3DC9mUKVeSkpLE1q2fAbB48Ubmz3+31tY9kxyLewi6JMP4yXB5D+8X/JVc6H4l1K3r/eX/4ffh\nyBF4bN6J953dFKbPgYPF0Kgx/Gg0bC886WXIrl+3y5ffRp8+807pORWFl0ZEIzDGD5ZHYCnGxpiT\nsEZgjLFGYIyxRmCMwcJLzRnExcReaXdHH8/2j+qdhLQ9AmOMNQJjjDUCYwzWCIwxWCMwxmCNwBiD\nNQJjDG5TjBsBC4BY4CzgIVV91dX6jDFV53KP4DZAVbUPkArMcrguY0wYXJ5Z+CnwneDt2ODyKUtM\njGP27KspLj5CbGwMd975AgUF/qaz+MnVeF3VjY9vSEbG9Rw6VEJsbAwjRjzH7t2fh13XpYEDOzB7\n9kASE/352xIIBJgwIZl77+1JUtJj7NlTXLVCLdrCT56AA/vg4AH4dAdcfpX3L8DUMTBoDCQPPPG+\nvZ+EvApXrwNnewSqmgm0FZHNwOvAj6tSJzq6LmPGvEhqahbLlm2he/c2vo7Tb67G66pupIWiugju\n9C1kNHUc5DwOU4bD9gKvCSx8BH422Ps6/gtf3n0hcvU6cNYIROQWYJuqfgvoCzxWlTobNuymtBTy\n89Po27c9mZnrfR2n31yN11XdSAtFdRHc6VvI6KFiaByMMIuKgvYXwtVpMGUhTJgNdet5/1fefSFy\n9TpwOUfQHXgVQFX/DbQSkTpVKVRYuI9+/eaTnf0+Eyd283OMTrgar6u6kRKK6iq40zeLpkOnnnBv\nBiS08f7y//YOmHIz7P8vDLgFXnrqm/edIhevA5eNYDNwOYCItMNLMz56qkXS07vTv7/3YRI7duwn\nLi7G10H6zdV4XdWNpFBUV8GdvmkaD5nT4Dej4GgJfHHI+xfg831Qtz5cmPzN+06Bq9eBs8zC4NuH\nTwEt8CYlf66qyyocSAWZha1bn82cOddRXHyExo3rM3r0C74eH/rN1Xhd1Y3UUNSqBHdWJJyQ0RMu\nQ27RBu5/Gj4rgo83wdtL4ZafepOHAA+neY3g6/cd+ubkZEWXIYf7OrDwUmMciLQ8AgsvNcZUyBqB\nMcYagTHGGoExBmsExhjsXQNzRjm1s/hCc8RBTSjt4ObdCD4otXcNjDHls0ZgjLFGYIyxRmCMwRqB\nMQZrBMYYrBEYY3CbYhwFPAF0BL4AxqjqRlfrM8ZUncs9ghSgiapeAYwCpjpclzEmDC4bQQdgNYCq\nFgDtqhpVZry04dzc4WRl3ciSJSNJSGjoW+2BAztQUDDet3qR6OGHr+T551PJzx9BYmKsb3V92bat\n2sKTeTDjr/Dwn6FLT/jj3+BXf4LfPwuNzob234YnX4bZ2fBELkSfWnKRy0awDhggInVERIDzgeYO\n13dac5U27CIVONJcdlkrWrVqxJAh2Ywa9SLHjvlztrtv2/bWcfCXx2HCcNhWAPfPgkVz4P47Yec2\nSPoOXHAJPJoO41Lh4y1w6anFuLmMM38Zb4/gdeBHwH+Acs9zNpVzlTbsIhU40lx2WSsOHTrKH/5w\nFb/8ZW8OHz7laM1y+bZtDxZD02A6ciAKXlgIP3kEZmVBh47wzj/gpUzQdRDTADpcCO+vOaVVOH3X\nQFXvV9Xuqno33oechBkcf2bzO2241qcCV5OYmLrs3XuQsWNf4S9/2cD993cPu6av23budO9w4NcZ\ncE4bmPwoPDgGxg+Ft16HgUO9x7VpD1OfgYd/BP/dc0qrcPm5Bp1E5Kng7auANap6zNX6Tncu0oZr\nfSpwNVm3roioKG9ndf/+w9SrF/5Ulq/bNi4enpoGPwumI69a/tUv+r69EJcA57aDyVO9x3xw6p91\n4DLFOAovxfgC4BAwQlULKxyIXYZ8Uq7Thv1MBa69Kr4M+Y9/vJqmTc8iNjaa8eOXoBrqX9TKL0Ou\nyrY94TLkc9rAo0/D3iL4aBO8/CyMmwJ7d0PjpnDfHd68QbsO3n0Ai/4EK17+ZuEKLkO2PAJzBrE8\nAssjMMZUyBqBMcYagTHGGoExBmsExhhq0bsGxpiaY3sExhhrBMYYawTGGKwRGGOwRmCMwRqBMQZr\nBMYYHKYYuyAiM4BkoBQYr6pv+VS3I/A3YIaqPuZHzWDdR4CeeNv5N6r6fJj1GgDzgBZANPBLVX0x\n3HGWqR8DrA/WnedDvSuBZ4ENwbvWqeq4cOsGa48A0oES4AFVfcmHmqOAW8vc1UVVG4VZsxGwAC+Y\n5yzgIVV9NZyawbq+poRHzB6BiPQGOqhqN7xU5N/7VLchMBvI96Nembp9gI7B8V4FzPSh7HXA26ra\nGxgKTPehZln3A37HFa1Q1SuDX341gWbAg0AP4Fq8xOywqWrG8bEG68/3oextXmntA6QCs3yoCT6n\nhEdMIwD6AYsBVPU/QKyInO1pHZt6AAAEPUlEQVRD3cPAQGCHD7XKeh24MXj7M6BhuCnOqrpIVR8J\nLrYBPg6nXlkikoQXIhP2X9Zq8F1gqaruV9Wdqnqng3U8APzShzqfAs2Ct2ODy37wNSU8kg4NWgLv\nlFkuCt73v3CKqmoJUOIFLftHVY8CnwcXRwF5wfvCJiJvAq3x/hr6ZRrwAyDNx5oAF4hILhCHt1u8\nxIea5wENgnVjgSmq6tsenYh0BQpVdVe4tVQ1U0RuE5HNeGO9JuwBetYBE0RkJvAtvkoJ/6QqxSJp\nj+DrIiIRWURS8BrBD/yqGdwdvB54RkTC3g4iMhL4p6puCXtwJ9oEPIS3G5sGZIhIfR/qBvD+yg7B\n2/We68d2KOMOvLmYsInILcA2Vf0W0BfwZQ7K75TwSNoj2IG3B3BcK2BnDY0lJCIyALgPuEpVw/7g\nABG5FNitqoWq+q6I1AXiCT8d+hrgfBG5Fm9P47CIfKyqS8MpqqrbgUXBxQIR2QWcC4TbcD4B3gzu\nzRWIyH782Q7HXQn4Mp8BdAdeBVDVf4tIKxGp48feoaref/y2iBQQxvcfSXsEf8ebbEFELgF2qOr+\nmh1SxUSkCfAocK2q+jUB1wuYFKzfAmiED8ecqjpMVbuqajLwJN67BmE1geAYR4jIj4O3W+K927E9\n3Lp4r4W+IhIVnDj0ZTsAiEgr4ICqfuFHPWAzcHmwdrtg7bCbgN8p4RGzR6Cqb4rIO8Hj42PAWD/q\nBv/KTsM77jwiIqnAEB9+eYfhHbNllZl/GKmq28Ko+QTe7vVKIAYYW8sj4nOBhcHDo/rA3X78gqnq\ndhHJBlYF7xrn43Y4B38/f2MO8JSIrMD7fRvjU911QJSIrCaYEh5OMcsjMMZE1KGBMcYRawTGGGsE\nxhhrBMYYrBEYY7BGYAAROUdESkTkpyE89pYw1lMaPAnK1DLWCAx4p/++j3e6boVE5Fz8ex/c1CLW\nnQ3A94G7gXkickXw5K3L8S6d/gLv0uSRwELgIhFZgPeR979S1R4AIjIPeENVnxSRX+BdLQreFZK3\nqKqbjw02vrA9gjOciPTC+4OwDC9A4/bgfz0DjA5mH6zAux7hQbxwkZEnqVcXKAZ6qmp3oCkwwN13\nYPxgjcCMAuapaikwFxgqIm2Bpqq6HkBVZ6pqZijFghcCHQVWBk+r7Yx3qrWpxezQ4AwWDHa5Adgm\nIkOCd9cB+lD5H4mvn5teP1izO96hRhdV/Tx4TYCp5awRnNmG40WJfRmWISI3412P/6mIdFXVt0Rk\nEnAQL8+wXvCh/wPODeYAxOBdYbcM7wrDrcEm0A4vY9KPMBLjkF10dAYLXrn2i7IBqMHgkG14wScz\ngSN4UWu34jWBd/ACRwYAOUBbvEttD+HNJWTiXX9fihda+hZe7Nd3AQXqBQ8fTC1ijcAYY5OFxhhr\nBMYYrBEYY7BGYIzBGoExBmsExhisERhjgP8HqEi/Pmv+UUoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f250123b3c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CHovy7z0NO4h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Our prediction result on test data are further improved too! - 1.5% error now**\n"
      ]
    },
    {
      "metadata": {
        "id": "_c0UWJu8OuI_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now using Pickle to export binary object for benchmark experiment usage**"
      ]
    },
    {
      "metadata": {
        "id": "sSkmXfsGM4k6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "5c0494a1-ae94-4cc9-c1bd-166809f55c8b"
      },
      "cell_type": "code",
      "source": [
        "# check data for pickle dump\n",
        "print('\\ntrain_data object:', type(train_data), train_data.shape)    \n",
        "print('\\ntrain_labels object:', type(train_labels),  train_labels.shape)  \n",
        "print('\\nvalidation_data object:', type(validation_data),  validation_data.shape)  \n",
        "print('\\nvalidation_labels object:', type(validation_labels),  validation_labels.shape)  \n",
        "print('\\ntest_data object:', type(test_data),  test_data.shape)  \n",
        "print('\\ntest_labels object:', type(test_labels),  test_labels.shape)  "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train_data object: <class 'numpy.ndarray'> (55000, 28, 28, 1)\n",
            "\n",
            "train_labels object: <class 'numpy.ndarray'> (55000, 10)\n",
            "\n",
            "validation_data object: <class 'numpy.ndarray'> (5000, 28, 28, 1)\n",
            "\n",
            "validation_labels object: <class 'numpy.ndarray'> (5000, 10)\n",
            "\n",
            "test_data object: <class 'numpy.ndarray'> (10000, 28, 28, 1)\n",
            "\n",
            "test_labels object: <class 'numpy.ndarray'> (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MfkDhupxO_6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7974e51e-60ac-4092-ced2-a1a6e571601a"
      },
      "cell_type": "code",
      "source": [
        "import pickle  # used for dumping and loading binary files\n",
        "\n",
        "# define collection of objects to export as binary file using pickle.\n",
        "data = {\n",
        "    'train_data': train_data,\n",
        "    'train_labels': train_labels,\n",
        "    'validation_data': validation_data,\n",
        "    'validation_labels': validation_labels,\n",
        "    'test_data': test_data,\n",
        "    'test_labels': test_labels}\n",
        "\n",
        "# write to binary file\n",
        "with open('mnist_data.pickle', 'wb') as f:\n",
        "    # Pickle the 'data' dictionary using the highest protocol available.\n",
        "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print('\\n Run complete. data objects sent to binary file  mnist_data.pickle')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Run complete. data objects sent to binary file  mnist_data.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vVZ81CznPHds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "e4160a13-1970-489c-c841-e6e60a03cc77"
      },
      "cell_type": "code",
      "source": [
        "with open('mnist_data.pickle', 'rb') as f:\n",
        "    # The protocol version used is detected automatically, so we do not\n",
        "    # have to specify it.\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# extract objects from the dictionary object data\n",
        "train_data = data['train_data']\n",
        "train_labels = data['train_labels'] \n",
        "validation_data = data['validation_data'] \n",
        "validation_labels = data['validation_labels'] \n",
        "test_data = data['test_data'] \n",
        "test_labels = data['test_labels']  \n",
        "    \n",
        "# check data from pickle load\n",
        "print('\\ntrain_data object:', type(train_data), train_data.shape)    \n",
        "print('\\ntrain_labels object:', type(train_labels),  train_labels.shape)  \n",
        "print('\\nvalidation_data object:', type(validation_data),  validation_data.shape)  \n",
        "print('\\nvalidation_labels object:', type(validation_labels),  validation_labels.shape)  \n",
        "print('\\ntest_data object:', type(test_data),  test_data.shape)  \n",
        "print('\\ntest_labels object:', type(test_labels),  test_labels.shape)  \n",
        "\n",
        "print('\\ndata input complete')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train_data object: <class 'numpy.ndarray'> (55000, 28, 28, 1)\n",
            "\n",
            "train_labels object: <class 'numpy.ndarray'> (55000, 10)\n",
            "\n",
            "validation_data object: <class 'numpy.ndarray'> (5000, 28, 28, 1)\n",
            "\n",
            "validation_labels object: <class 'numpy.ndarray'> (5000, 10)\n",
            "\n",
            "test_data object: <class 'numpy.ndarray'> (10000, 28, 28, 1)\n",
            "\n",
            "test_labels object: <class 'numpy.ndarray'> (10000, 10)\n",
            "\n",
            "data input complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ij1oBvpaPOuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# user-defined function to convert binary digits to digits 0-9\n",
        "# add digits to the end of our label data\n",
        "\n",
        "def label_transform(y_in):\n",
        "    for i in range(len(y_in)):\n",
        "        if (y_in[i] == 1): return i\n",
        "\n",
        "y_train = []    \n",
        "for j in range(train_labels.shape[0]):\n",
        "    y_train.append(label_transform(train_labels[j,]))  \n",
        "y_train = np.asarray(y_train)    \n",
        "\n",
        "y_validation = []    \n",
        "for j in range(validation_labels.shape[0]):\n",
        "    y_validation.append(label_transform(validation_labels[j,]))  \n",
        "y_validation = np.asarray(y_validation)    \n",
        "\n",
        "y_test = []    \n",
        "for j in range(test_labels.shape[0]):\n",
        "    y_test.append(label_transform(test_labels[j,]))  \n",
        "y_test = np.asarray(y_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_DfytmaPpsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 28x28 matrix of entries converted to vector of 784 entries    \n",
        "X_train = train_data.reshape(55000, 784)\n",
        "X_validation = validation_data.reshape(5000, 784)    \n",
        "X_test = test_data.reshape(10000, 784) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIC5gnJWPuSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "5cc06264-c72d-4d1b-cb7d-7f80042961f8"
      },
      "cell_type": "code",
      "source": [
        "# check data intended for Scikit Learn input\n",
        "print('\\nX_train object:', type(X_train), X_train.shape)    \n",
        "print('\\ny_train object:', type(y_train),  y_train.shape)  \n",
        "print('\\nX_validation object:', type(X_validation),  X_validation.shape)  \n",
        "print('\\ny_validation object:', type(y_validation),  y_validation.shape)  \n",
        "print('\\nX_test object:', type(X_test),  X_test.shape)  \n",
        "print('\\ny_test object:', type(y_test),  y_test.shape)   "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "X_train object: <class 'numpy.ndarray'> (55000, 784)\n",
            "\n",
            "y_train object: <class 'numpy.ndarray'> (55000,)\n",
            "\n",
            "X_validation object: <class 'numpy.ndarray'> (5000, 784)\n",
            "\n",
            "y_validation object: <class 'numpy.ndarray'> (5000,)\n",
            "\n",
            "X_test object: <class 'numpy.ndarray'> (10000, 784)\n",
            "\n",
            "y_test object: <class 'numpy.ndarray'> (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g2sRULqlPx_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "3ca643be-4e02-41c9-f3fc-21a2d641bb85"
      },
      "cell_type": "code",
      "source": [
        "# Scikit Learn MLP Classification does validation internally, \n",
        "# so there is with no need for a separate validation set.\n",
        "# We will combine the train and validation sets.\n",
        "\n",
        "X_train_expanded = np.vstack((X_train, X_validation))\n",
        "y_train_expanded = np.vstack((y_train.reshape(55000,1), y_validation.reshape(5000,1)))\n",
        "\n",
        "print('\\nX_train_expanded object:', type(X_train_expanded),  X_train_expanded.shape)  \n",
        "print('\\ny_train_expanded object:', type(y_train_expanded), y_train_expanded.shape)  "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "X_train_expanded object: <class 'numpy.ndarray'> (60000, 784)\n",
            "\n",
            "y_train_expanded object: <class 'numpy.ndarray'> (60000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hpyw4pBsP9M5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Below build up our Scikit Learn MLPClassifier model as benchmark**"
      ]
    },
    {
      "metadata": {
        "id": "0E1QmObqP6Ek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 9999\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1SpOWHkQMA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "names = ['ANN-2-Layers-10-Nodes-per-Layer',\n",
        "         'ANN-2-Layers-20-Nodes-per-Layer',\n",
        "         'ANN-5-Layers-10-Nodes-per-Layer',\n",
        "         'ANN-5-Layers-20-Nodes-per-Layer']\n",
        "\n",
        "layers = [2, 2, 5, 5]\n",
        "nodes_per_layer = [10, 20, 10, 20]\n",
        "treatment_condition = [(10, 10), \n",
        "                       (20, 20), \n",
        "                       (10, 10, 10, 10, 10), \n",
        "                       (20, 20, 20, 20, 20)] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrKhAZysQQn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# note that validation is included in the method  \n",
        "# for validation_fraction 0.083333, note that 60000 * 0.83333 = 5000    \n",
        "methods = [MLPClassifier(hidden_layer_sizes=treatment_condition[0], activation='relu', \n",
        "              solver='adam', alpha=0.0001, batch_size='auto', \n",
        "              learning_rate='constant', learning_rate_init=0.001, \n",
        "              power_t=0.5, max_iter=200, shuffle=True, \n",
        "              random_state=RANDOM_SEED, \n",
        "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
        "              nesterovs_momentum=True, early_stopping=False, \n",
        "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "    MLPClassifier(hidden_layer_sizes=treatment_condition[1], activation='relu', \n",
        "              solver='adam', alpha=0.0001, batch_size='auto', \n",
        "              learning_rate='constant', learning_rate_init=0.001, \n",
        "              power_t=0.5, max_iter=200, shuffle=True, \n",
        "              random_state=RANDOM_SEED, \n",
        "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
        "              nesterovs_momentum=True, early_stopping=False, \n",
        "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "    MLPClassifier(hidden_layer_sizes=treatment_condition[2], activation='relu', \n",
        "              solver='adam', alpha=0.0001, batch_size='auto', \n",
        "              learning_rate='constant', learning_rate_init=0.001, \n",
        "              power_t=0.5, max_iter=200, shuffle=True, \n",
        "              random_state=RANDOM_SEED, \n",
        "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
        "              nesterovs_momentum=True, early_stopping=False, \n",
        "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
        "    MLPClassifier(hidden_layer_sizes=treatment_condition[3], activation='relu', \n",
        "              solver='adam', alpha=0.0001, batch_size='auto', \n",
        "              learning_rate='constant', learning_rate_init=0.001, \n",
        "              power_t=0.5, max_iter=200, shuffle=True, \n",
        "              random_state=RANDOM_SEED, \n",
        "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
        "              nesterovs_momentum=True, early_stopping=False, \n",
        "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sF97XV1jQq0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   validation_fraction 0.083333; 60000*0.833=5000; so validation size fits what is used in neural network\n",
        "*   solver = 'adam'\n",
        "*   activation = 'relu', fitting used in neural network\n",
        "*   test 4 different structure\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4YGPFdsBQbJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1216
        },
        "outputId": "1925da1d-1e75-4b2b-dbde-49a9909f5a2c"
      },
      "cell_type": "code",
      "source": [
        "index_for_method = 0 \n",
        "training_performance_results = []\n",
        "test_performance_results = []\n",
        "processing_time = []\n",
        "   \n",
        "for name, method in zip(names, methods):\n",
        "    print('\\n------------------------------------')\n",
        "    print('\\nMethod:', name)\n",
        "    print('\\n  Specification of method:', method)\n",
        "    start_time = time.clock()\n",
        "    method.fit(X_train, y_train)\n",
        "    end_time = time.clock()\n",
        "    runtime = end_time - start_time  # seconds of wall-clock time \n",
        "    print(\"\\nProcessing time (seconds): %f\" % runtime)        \n",
        "    processing_time.append(runtime)\n",
        "\n",
        "    # mean accuracy of prediction in training set\n",
        "    training_performance = method.score(X_train_expanded, y_train_expanded)\n",
        "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
        "    training_performance_results.append(training_performance)\n",
        "\n",
        "    # mean accuracy of prediction in test set\n",
        "    test_performance = method.score(X_test, y_test)\n",
        "    print(\"\\nTest set accuracy: %f\" % test_performance)\n",
        "    test_performance_results.append(test_performance)\n",
        "                \n",
        "    index_for_method += 1"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------\n",
            "\n",
            "Method: ANN-2-Layers-10-Nodes-per-Layer\n",
            "\n",
            "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
            "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
            "       nesterovs_momentum=True, power_t=0.5, random_state=9999,\n",
            "       shuffle=True, solver='adam', tol=0.0001,\n",
            "       validation_fraction=0.083333, verbose=False, warm_start=False)\n",
            "\n",
            "Processing time (seconds): 135.987975\n",
            "\n",
            "Training set accuracy: 0.934983\n",
            "\n",
            "Test set accuracy: 0.927300\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "Method: ANN-2-Layers-20-Nodes-per-Layer\n",
            "\n",
            "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
            "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
            "       nesterovs_momentum=True, power_t=0.5, random_state=9999,\n",
            "       shuffle=True, solver='adam', tol=0.0001,\n",
            "       validation_fraction=0.083333, verbose=False, warm_start=False)\n",
            "\n",
            "Processing time (seconds): 218.264116\n",
            "\n",
            "Training set accuracy: 0.966950\n",
            "\n",
            "Test set accuracy: 0.951700\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "Method: ANN-5-Layers-10-Nodes-per-Layer\n",
            "\n",
            "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "       hidden_layer_sizes=(10, 10, 10, 10, 10), learning_rate='constant',\n",
            "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
            "       nesterovs_momentum=True, power_t=0.5, random_state=9999,\n",
            "       shuffle=True, solver='adam', tol=0.0001,\n",
            "       validation_fraction=0.083333, verbose=False, warm_start=False)\n",
            "\n",
            "Processing time (seconds): 149.282256\n",
            "\n",
            "Training set accuracy: 0.943900\n",
            "\n",
            "Test set accuracy: 0.933000\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "Method: ANN-5-Layers-20-Nodes-per-Layer\n",
            "\n",
            "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "       hidden_layer_sizes=(20, 20, 20, 20, 20), learning_rate='constant',\n",
            "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
            "       nesterovs_momentum=True, power_t=0.5, random_state=9999,\n",
            "       shuffle=True, solver='adam', tol=0.0001,\n",
            "       validation_fraction=0.083333, verbose=False, warm_start=False)\n",
            "\n",
            "Processing time (seconds): 118.972399\n",
            "\n",
            "Training set accuracy: 0.964783\n",
            "\n",
            "Test set accuracy: 0.952200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-BvOxqiDRr-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "75345d7f-6e22-4555-af1f-423bc6d38c02"
      },
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict  \n",
        "\n",
        "results = pd.DataFrame(OrderedDict([('Method Name', names),\n",
        "                        ('Layers', layers),\n",
        "                        ('Nodes per Layer', nodes_per_layer),\n",
        "                        ('Processing Time', processing_time),\n",
        "                        ('Training Set Accuracy', training_performance_results),\n",
        "                        ('Test Set Accuracy', test_performance_results)]))\n",
        "\n",
        "print('\\nBenchmark Experiment: Scikit Learn Artificial Neural Networks\\n')\n",
        "print(results) "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmark Experiment: Scikit Learn Artificial Neural Networks\n",
            "\n",
            "                       Method Name  Layers  Nodes per Layer  Processing Time  \\\n",
            "0  ANN-2-Layers-10-Nodes-per-Layer       2               10       135.987975   \n",
            "1  ANN-2-Layers-20-Nodes-per-Layer       2               20       218.264116   \n",
            "2  ANN-5-Layers-10-Nodes-per-Layer       5               10       149.282256   \n",
            "3  ANN-5-Layers-20-Nodes-per-Layer       5               20       118.972399   \n",
            "\n",
            "   Training Set Accuracy  Test Set Accuracy  \n",
            "0               0.934983             0.9273  \n",
            "1               0.966950             0.9517  \n",
            "2               0.943900             0.9330  \n",
            "3               0.964783             0.9522  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PbTGynrJTCFD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}