{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict422Week4_KunYang.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/bluebottle66/Practical-Machine-Learning-Northwestern-/blob/master/Predict422Week4_KunYang.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YIbOaaxz8Ffw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn.linear_model\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt # for root mean-squared error calculation\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor  # machine learning tree\n",
        "from sklearn.ensemble import RandomForestRegressor # ensemble method\n",
        "\n",
        "RANDOM_SEED = 1\n",
        "SET_FIT_INTERCEPT = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2n1JKZZ_qGC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url=\"https://raw.githubusercontent.com/bluebottle66/Practical-Machine-Learning-Northwestern-/master/boston.csv\"\n",
        "boston_input = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DjUFmh7h_7j8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read and Process data**\n",
        "\n",
        "- Switch to github link to store csv files\n",
        "- Look at data statistics, drop n/a, drop neighborhood\n",
        "- Create a new response variable for Log median value of homes in thousands of 1970 dollars\n",
        "- Create preliminary dataset\n",
        "- Perform Standard Scaler of original data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XUfGRXtk_6O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5297a761-b877-4ef0-fb5e-ec28fc0817e7"
      },
      "cell_type": "code",
      "source": [
        "boston = boston_input.drop('neighborhood', 1)\n",
        "\n",
        "boston.dropna()\n",
        "\n",
        "#create log transformation for response variable\n",
        "boston['logMv']=np.log(boston['mv'])\n",
        "\n",
        "prelim_model_data = np.array([boston.mv,\\\n",
        "boston.logMv,\\\n",
        "boston.crim,\\\n",
        "boston.zn,\\\n",
        "boston.indus,\\\n",
        "boston.chas,\\\n",
        "boston.nox,\\\n",
        "boston.rooms,\\\n",
        "boston.age,\\\n",
        "boston.dis,\\\n",
        "boston.rad,\\\n",
        "boston.tax,\\\n",
        "boston.ptratio,\\\n",
        "boston.lstat]).T\n",
        "\n",
        "# dimensions of the polynomial model X input and y response\n",
        "# preliminary data before standardization\n",
        "print('\\nData dimensions:', prelim_model_data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Data dimensions: (506, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fUk4vvEVAe5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "a831e25f-af59-42aa-ec62-1ba06cd10aca"
      },
      "cell_type": "code",
      "source": [
        "#Data transformation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(prelim_model_data))\n",
        "\n",
        "# show standardization constants being employed\n",
        "print(scaler.mean_)\n",
        "print(scaler.scale_)\n",
        "\n",
        "# the model data will be standardized form of preliminary model data\n",
        "model_data = scaler.fit_transform(prelim_model_data)\n",
        "\n",
        "# dimensions of the polynomial model X input and y response\n",
        "# all in standardized units of measure\n",
        "print('\\nDimensions for model_data:', model_data.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[2.25288538e+01 3.03455800e+00 3.61352356e+00 1.13636364e+01\n",
            " 1.11367787e+01 6.91699605e-02 5.54695059e-01 6.28463439e+00\n",
            " 6.85749012e+01 3.79504269e+00 9.54940711e+00 4.08237154e+02\n",
            " 1.84555336e+01 1.26530632e+01]\n",
            "[9.17309810e+00 4.07871084e-01 8.59304135e+00 2.32993957e+01\n",
            " 6.85357058e+00 2.53742935e-01 1.15763115e-01 7.01922514e-01\n",
            " 2.81210326e+01 2.10362836e+00 8.69865112e+00 1.68370495e+02\n",
            " 2.16280519e+00 7.13400164e+00]\n",
            "\n",
            "Dimensions for model_data: (506, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pdO8q8xXA007",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Build up and Data Analysis:**\n",
        "\n",
        "Look at correlation matrix - analyzing the factors which impact the value\n",
        "\n",
        "Build up 4 regression models (linear, ridge, lasso and elastic net) on  log transform of home values (from previous week)\n",
        "\n",
        "\n",
        "Build up Decision Tree Regressor models\n",
        "\n",
        "Build up Random Forecasts models\n",
        "\n",
        "\n",
        "Evaluate with cross-validation"
      ]
    },
    {
      "metadata": {
        "id": "fJc0veIJAqmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "0006950c-b0bc-4540-9c99-75b9702e226c"
      },
      "cell_type": "code",
      "source": [
        "corr=boston.corr()\n",
        "print(corr[(corr>0.5)|(corr<-0.5)])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             crim        zn     indus  chas       nox     rooms       age  \\\n",
            "crim     1.000000       NaN       NaN   NaN       NaN       NaN       NaN   \n",
            "zn            NaN  1.000000 -0.533828   NaN -0.516604       NaN -0.569537   \n",
            "indus         NaN -0.533828  1.000000   NaN  0.763651       NaN  0.644779   \n",
            "chas          NaN       NaN       NaN   1.0       NaN       NaN       NaN   \n",
            "nox           NaN -0.516604  0.763651   NaN  1.000000       NaN  0.731470   \n",
            "rooms         NaN       NaN       NaN   NaN       NaN  1.000000       NaN   \n",
            "age           NaN -0.569537  0.644779   NaN  0.731470       NaN  1.000000   \n",
            "dis           NaN  0.664408 -0.708027   NaN -0.769230       NaN -0.747881   \n",
            "rad      0.625505       NaN  0.595129   NaN  0.611441       NaN       NaN   \n",
            "tax      0.582764       NaN  0.720760   NaN  0.668023       NaN  0.506456   \n",
            "ptratio       NaN       NaN       NaN   NaN       NaN       NaN       NaN   \n",
            "lstat         NaN       NaN  0.603800   NaN  0.590879 -0.613808  0.602339   \n",
            "mv            NaN       NaN       NaN   NaN       NaN  0.696304       NaN   \n",
            "logMv   -0.530001       NaN -0.543195   NaN -0.513431  0.632536       NaN   \n",
            "\n",
            "              dis       rad       tax   ptratio     lstat        mv     logMv  \n",
            "crim          NaN  0.625505  0.582764       NaN       NaN       NaN -0.530001  \n",
            "zn       0.664408       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "indus   -0.708027  0.595129  0.720760       NaN  0.603800       NaN -0.543195  \n",
            "chas          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "nox     -0.769230  0.611441  0.668023       NaN  0.590879       NaN -0.513431  \n",
            "rooms         NaN       NaN       NaN       NaN -0.613808  0.696304  0.632536  \n",
            "age     -0.747881       NaN  0.506456       NaN  0.602339       NaN       NaN  \n",
            "dis      1.000000       NaN -0.534432       NaN       NaN       NaN       NaN  \n",
            "rad           NaN  1.000000  0.910228       NaN       NaN       NaN       NaN  \n",
            "tax     -0.534432  0.910228  1.000000       NaN  0.543993       NaN -0.566214  \n",
            "ptratio       NaN       NaN       NaN  1.000000       NaN -0.505655       NaN  \n",
            "lstat         NaN       NaN  0.543993       NaN  1.000000 -0.740836 -0.809234  \n",
            "mv            NaN       NaN       NaN -0.505655 -0.740836  1.000000  0.952967  \n",
            "logMv         NaN       NaN -0.566214       NaN -0.809234  0.952967  1.000000  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ofK-eMNGCgZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create list of regression models and all factors in our regression model\n",
        "\n",
        "names = ['Linear_Regression', 'Ridge_Regression','Lasso_Regression','Elastic_Net_Regression','Decision_Tree','Random_Forest']\n",
        "variables=['crim','zn','indus','chas','nox','romms','age','dis','rad','tax','ptratio','lstat']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBcZtRurDCmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "regressors = [LinearRegression(fit_intercept = SET_FIT_INTERCEPT),\n",
        "              Ridge(alpha = 1, solver = 'cholesky',\n",
        "                fit_intercept = SET_FIT_INTERCEPT,\n",
        "                normalize = False,\n",
        "                random_state = RANDOM_SEED),\n",
        "              Lasso(alpha = 0.1, max_iter=10000, tol=0.01,\n",
        "                fit_intercept = SET_FIT_INTERCEPT,\n",
        "                random_state = RANDOM_SEED),\n",
        "              ElasticNet(alpha = 0.1, l1_ratio = 0.5,\n",
        "                max_iter=10000, tol=0.01,\n",
        "                fit_intercept = SET_FIT_INTERCEPT,\n",
        "                normalize = False,\n",
        "                random_state = RANDOM_SEED),\n",
        "              DecisionTreeRegressor(random_state = RANDOM_SEED, \n",
        "                max_features=\"log2\"),\n",
        "              RandomForestRegressor(random_state = RANDOM_SEED, \n",
        "                max_features=\"log2\",\n",
        "                n_estimators=100,\n",
        "                bootstrap=True)\n",
        "             ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gPiueTAvEfyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N_FOLDS = 10\n",
        "N_Variables=12\n",
        "\n",
        "# set up numpy array for storing results\n",
        "\n",
        "cv_results = np.zeros((N_FOLDS, len(names)))\n",
        "rsquare_results = np.zeros((N_FOLDS, len(names)))\n",
        "importance_results=np.zeros((N_FOLDS,N_Variables,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QaGhDT9IE7t6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = N_FOLDS, shuffle=False, random_state = RANDOM_SEED)\n",
        "# check the splitting process by looking at fold observation counts\n",
        "index_for_fold = 0 # fold count initialized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BeXEMkw2FAYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8870
        },
        "outputId": "a9838997-2e55-448f-cace-8e2beca314c2"
      },
      "cell_type": "code",
      "source": [
        "for train_index, test_index in kf.split(model_data):\n",
        "  \n",
        "  print('\\nFold index:', index_for_fold,\n",
        "  '------------------------------------------')\n",
        "\n",
        "  X_train = model_data[train_index, 2:model_data.shape[1]]\n",
        "  X_test = model_data[test_index, 2:model_data.shape[1]]\n",
        "  y_train = model_data[train_index, 1]\n",
        "  y_test = model_data[test_index, 1]\n",
        "  # note, if using raw response variable, we shalll use model_data[train_index, 0] here\n",
        "\n",
        "  print('\\nShape of input data for this fold:',\n",
        "        '\\nData Set: (Observations, Variables)')\n",
        "  print('X_train:', X_train.shape)\n",
        "  print('X_test:',X_test.shape)\n",
        "  print('y_train:', y_train.shape)\n",
        "  print('y_test:',y_test.shape)\n",
        "\n",
        "  index_for_method = 0 # initialize\n",
        "\n",
        "  for name, reg_model in zip(names, regressors):\n",
        "    \n",
        "      print('\\nRegression model evaluation for:', name)\n",
        "      print(' Scikit Learn method:', reg_model)\n",
        "      reg_model.fit(X_train, y_train) # fit on the train set for this fold\n",
        "\n",
        "      # evaluate on the test set for this fold\n",
        "      y_test_predict = reg_model.predict(X_test)\n",
        "      \n",
        "      r2_result = r2_score(y_test, y_test_predict)\n",
        "\n",
        "      fold_method_result = sqrt(mean_squared_error(y_test, y_test_predict))\n",
        "\n",
        "      print(reg_model.get_params(deep=True))\n",
        "      print('Root mean-squared error:', fold_method_result)\n",
        "      \n",
        "      rsquare_results[index_for_fold, index_for_method] =r2_result\n",
        "\n",
        "      cv_results[index_for_fold, index_for_method] = fold_method_result\n",
        "      \n",
        "      if name == 'Decision_Tree':\n",
        "        importance_results[index_for_fold,:,0] = reg_model.feature_importances_[:]\n",
        "        \n",
        "      if name == 'Random_Forest':\n",
        "        importance_results[index_for_fold,:,1] = reg_model.feature_importances_[:]\n",
        "      \n",
        "      index_for_method += 1\n",
        "\n",
        "  index_for_fold += 1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold index: 0 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (455, 12)\n",
            "X_test: (51, 12)\n",
            "y_train: (455,)\n",
            "y_test: (51,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.2957195904826947\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.2951112840301624\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.3220857420288324\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.3135510808714884\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.47040739062596604\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.4290119396001153\n",
            "\n",
            "Fold index: 1 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (455, 12)\n",
            "X_test: (51, 12)\n",
            "y_train: (455,)\n",
            "y_test: (51,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.3557362987584146\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.3533939236562825\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.2872794163014753\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.27921963841201985\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.33712136661448217\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.21509307662539015\n",
            "\n",
            "Fold index: 2 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (455, 12)\n",
            "X_test: (51, 12)\n",
            "y_train: (455,)\n",
            "y_test: (51,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.5090599995431104\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.505277177047064\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.34386373299140577\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.3356351274891151\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.4441260606770143\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.23791379466420023\n",
            "\n",
            "Fold index: 3 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (455, 12)\n",
            "X_test: (51, 12)\n",
            "y_train: (455,)\n",
            "y_test: (51,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.4245560044773553\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.4247130974719131\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.570869982006579\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.5326628081338625\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.7865710865278288\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.44304146906302777\n",
            "\n",
            "Fold index: 4 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (455, 12)\n",
            "X_test: (51, 12)\n",
            "y_train: (455,)\n",
            "y_test: (51,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.4644772466725289\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.4629341209714689\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.5417237970167682\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.48010564651726634\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.5683879436478869\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.33977215637950176\n",
            "\n",
            "Fold index: 5 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (455, 12)\n",
            "X_test: (51, 12)\n",
            "y_train: (455,)\n",
            "y_test: (51,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.34043009386943224\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.33935592038142515\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.5390255201821031\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.45135967797087667\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.7524177830869022\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.3841627914393369\n",
            "\n",
            "Fold index: 6 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (456, 12)\n",
            "X_test: (50, 12)\n",
            "y_train: (456,)\n",
            "y_test: (50,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.32213798129887583\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.3208411154730994\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.4112183782182908\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.394552178304764\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.5165411769605459\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.34082122703773043\n",
            "\n",
            "Fold index: 7 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (456, 12)\n",
            "X_test: (50, 12)\n",
            "y_train: (456,)\n",
            "y_test: (50,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 1.0808231208606516\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 1.0827906106205776\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 1.1901685515127212\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 1.179513221511315\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.9423218712616739\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.9254588906489777\n",
            "\n",
            "Fold index: 8 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (456, 12)\n",
            "X_test: (50, 12)\n",
            "y_train: (456,)\n",
            "y_test: (50,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.7523122168249469\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.7521139114041338\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.8171018817101936\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.7817808138820171\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.9827581504333699\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.6416672218058537\n",
            "\n",
            "Fold index: 9 ------------------------------------------\n",
            "\n",
            "Shape of input data for this fold: \n",
            "Data Set: (Observations, Variables)\n",
            "X_train: (456, 12)\n",
            "X_test: (50, 12)\n",
            "y_train: (456,)\n",
            "y_test: (50,)\n",
            "\n",
            "Regression model evaluation for: Linear_Regression\n",
            " Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
            "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
            "Root mean-squared error: 0.4192702311224106\n",
            "\n",
            "Regression model evaluation for: Ridge_Regression\n",
            " Scikit Learn method: Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "   normalize=False, random_state=1, solver='cholesky', tol=0.001)\n",
            "{'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
            "Root mean-squared error: 0.42039528131463105\n",
            "\n",
            "Regression model evaluation for: Lasso_Regression\n",
            " Scikit Learn method: Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
            "   normalize=False, positive=False, precompute=False, random_state=1,\n",
            "   selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.42071782791042467\n",
            "\n",
            "Regression model evaluation for: Elastic_Net_Regression\n",
            " Scikit Learn method: ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
            "      random_state=1, selection='cyclic', tol=0.01, warm_start=False)\n",
            "{'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 10000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 1, 'selection': 'cyclic', 'tol': 0.01, 'warm_start': False}\n",
            "Root mean-squared error: 0.4401673978347141\n",
            "\n",
            "Regression model evaluation for: Decision_Tree\n",
            " Scikit Learn method: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='log2',\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=1, splitter='best')\n",
            "{'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 1, 'splitter': 'best'}\n",
            "Root mean-squared error: 0.4607667717485033\n",
            "\n",
            "Regression model evaluation for: Random_Forest\n",
            " Scikit Learn method: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "           max_features='log2', max_leaf_nodes=None,\n",
            "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "           min_samples_leaf=1, min_samples_split=2,\n",
            "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
            "           oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
            "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
            "Root mean-squared error: 0.4881589713099916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uXBo1DsGGIBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "661756e2-7cfb-43d8-9574-00c644735395"
      },
      "cell_type": "code",
      "source": [
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "cv_results_df.columns = names\n",
        "print(cv_results_df.mean())\n",
        "\n",
        "r2_results_df = pd.DataFrame(rsquare_results)\n",
        "r2_results_df.columns = names\n",
        "print(r2_results_df.mean())\n",
        "\n",
        "importance_results_df = pd.DataFrame(np.mean(importance_results, axis=0))\n",
        "importance_results_df.index=variables\n",
        "print(importance_results_df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear_Regression         0.496452\n",
            "Ridge_Regression          0.495693\n",
            "Lasso_Regression          0.544405\n",
            "Elastic_Net_Regression    0.518855\n",
            "Decision_Tree             0.626142\n",
            "Random_Forest             0.444510\n",
            "dtype: float64\n",
            "Linear_Regression         0.374328\n",
            "Ridge_Regression          0.378451\n",
            "Lasso_Regression          0.339908\n",
            "Elastic_Net_Regression    0.404225\n",
            "Decision_Tree             0.032930\n",
            "Random_Forest             0.565667\n",
            "dtype: float64\n",
            "                0         1\n",
            "crim     0.063189  0.121718\n",
            "zn       0.018727  0.006724\n",
            "indus    0.037553  0.043005\n",
            "chas     0.003342  0.005803\n",
            "nox      0.061188  0.128171\n",
            "romms    0.099195  0.177683\n",
            "age      0.025785  0.037930\n",
            "dis      0.065897  0.068985\n",
            "rad      0.004943  0.022942\n",
            "tax      0.034062  0.048215\n",
            "ptratio  0.026371  0.057643\n",
            "lstat    0.559748  0.281183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IWQGTdj1HHKI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Result Analysis**\n",
        "\n",
        "- Random Forest model has the smallest mean square error and highest R-Square, so it is the best model to choose from the 6\n",
        "- Decision_Tree model seems have poor perfomance here\n",
        "- look at the feature importance of the 12 variables, the higher the value, the feature is more important: notice that when I built the model, I set the max_feature as log2, so log(12) = 4, max feature here is close to 4 factors, we can think that the top 3~4 feature importance are the most important factors to drive the home price in our Random Forest model\n",
        "\n",
        "\n",
        "> the top 4 important features are:\n",
        "   lstat, romms, nox and crim\n",
        "   So: % of lower income people; avg rooms in the house; air polution and crime rate\n",
        "   Not surpriseingly, we can find those 4 factors are indeed have higher absoluate correlation with house value from the correlation table\n",
        "    \n",
        "\n"
      ]
    }
  ]
}